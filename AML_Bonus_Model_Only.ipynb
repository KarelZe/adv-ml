{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KarelZe/adv-ml/blob/main/AML_Bonus_Model_Only.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYo468z6bYCA"
      },
      "source": [
        "# Notebooks for testing models only\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI96BIz_vgb5"
      },
      "source": [
        "%%capture\n",
        "!pip install -U imbalanced-learn\n",
        "!pip install -U yellowbrick"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpE9GKyY4o00"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, VotingClassifier, StackingClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LassoCV, LogisticRegression, lasso_path\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    balanced_accuracy_score,\n",
        "    classification_report,\n",
        "    matthews_corrcoef,\n",
        "    plot_confusion_matrix,\n",
        ")\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "from yellowbrick.classifier.rocauc import roc_auc\n",
        "\n",
        "# apply some custom styling to charts\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"rocket\", font_scale=1.1, color_codes=True)\n",
        "cmap = sns.cm.rocket\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# increase the number of rows displayed to fully display all (transposed) features.\n",
        "pd.options.display.max_rows = 1000\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpqVNyYl47RY"
      },
      "source": [
        "## Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj2lGS5C0PrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3821175-ee7f-471c-ac5d-b384f825e5b2"
      },
      "source": [
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# load proprocessed data\n",
        "X_train = pd.read_pickle(\"/content/drive/My Drive/AdvancedML/X_train.pkl\")\n",
        "y_train = pd.read_pickle(\"/content/drive/My Drive/AdvancedML/y_train.pkl\")\n",
        "\n",
        "X_test = pd.read_pickle(\"/content/drive/My Drive/AdvancedML/X_test.pkl\")\n",
        "y_test = pd.read_pickle(\"/content/drive/My Drive/AdvancedML/y_test.pkl\")    "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yze_Knjl5iLb"
      },
      "source": [
        "## Task 3: Use logistic regression (in-sample) for default prediction. Interpret your results for logistic regression. (20 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LbrUETSek4O"
      },
      "source": [
        "To compare the models in the end a DataFrame storing the performance metrics is created."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDF9PY7oelCJ"
      },
      "source": [
        "performance = pd.DataFrame()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fT0hckv5mOr"
      },
      "source": [
        "## Task 4: Compare logistic regression, classification tree, random forest, bagging, support vector machine (with two kernel functions), and neural network for default prediction based on the out-of-sample performance measures (at least three different measures). (35 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BS0Kw7ADLtSu"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9y8UWmYfmks"
      },
      "source": [
        "### Preliminary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQEwuNfrLtAA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-FA17cxj1gr"
      },
      "source": [
        "For model evaluation the same performance metrics are calculated. In contrast to the in-sampling method for Logistic Regression an out-of-sample approach is used by using separated data for training and testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0A6xby2O5rsq"
      },
      "source": [
        "def print_results(model, performance):\n",
        "    y_pred_model = model.predict(X_test)\n",
        "\n",
        "    print(classification_report(y_test, y_pred_model))\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(16, 9))\n",
        "    disp = plot_confusion_matrix(model, X_test, y_test, display_labels=['Non-Default', 'Default'], ax=ax)\n",
        "    plt.title(f\"Confusion matrix for {model.__class__.__name__}\")\n",
        "    disp.ax_.grid(False)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_model):.2f}\")\n",
        "    print(f\"Balanced Accuracy: {balanced_accuracy_score(y_test, y_pred_model):.2f}\")\n",
        "    print(f\"MCC: {matthews_corrcoef(y_test, y_pred_model):.2f}\")\n",
        "    print()\n",
        "    print(f\"Params: {model.get_params()}\")\n",
        "\n",
        "    performance_metrics = pd.DataFrame({'Accuracy': accuracy_score(y_test, y_pred_model),\n",
        "                                        'Balanced Accuracy': balanced_accuracy_score(y_test, y_pred_model),\n",
        "                                        'Matthews Corrcoef': matthews_corrcoef(y_test, y_pred_model)},\n",
        "                                       index=[f\"{model.__class__.__name__}\"])\n",
        "    performance = performance.append(performance_metrics)\n",
        "    return performance"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZ-cn3w1wVXt"
      },
      "source": [
        "# based on https://www.scikit-yb.org/en/latest/api/classifier/rocauc.html\n",
        "def print_performance_measures(model):\n",
        "    # Instantiate the visualizer with the classification model\n",
        "    plt.figure(figsize=(9, 9))\n",
        "    # FIXME: binary flag not working. Figure out why.\n",
        "    roc_auc(model, X_train, y_train, X_test=X_test, y_test=y_test, classes=[\"Default\", \"Non-Default\"], binary=True)\n",
        "    plt.show()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWJVWocXfhKX"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMS3VYLtI-n6"
      },
      "source": [
        "# max_depth = [2, 6, 10, 14...]\n",
        "min_depth = 2\n",
        "step_size = 4\n",
        "step_count = 2 ** 4\n",
        "max_depth = min_depth + np.arange(step_count) * step_size\n",
        "\n",
        "# perform grid search\n",
        "param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': max_depth}\n",
        "grid_dt = GridSearchCV(DecisionTreeClassifier(), param_grid, refit=True, verbose=0)\n",
        "grid_dt.fit(X_train, y_train)\n",
        "\n",
        "# choose best model\n",
        "grid_dt_optimized = grid_dt.best_estimator_\n",
        "\n",
        "# print confusion \n",
        "performance_metrics = print_results(grid_dt_optimized, performance)\n",
        "\n",
        "print_performance_measures(grid_dt_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sx4zqjHOC1qG"
      },
      "source": [
        "performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Do3bW0vVM8Uy"
      },
      "source": [
        "### Plot Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLGHivFHMrvC"
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(16, 9))\n",
        "tree.plot_tree(grid_dt_optimized, feature_names=X_train.columns, proportion=True, max_depth=2);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOaWDOhONCbS"
      },
      "source": [
        "### Plot feature importances of Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyu-ZGVvNBl0"
      },
      "source": [
        "def print_feature_importance(feature_importance):\n",
        "    \"\"\"\n",
        "    function to create a paretto plot with the gini importance of features.\n",
        "    \"\"\"\n",
        "    feature_importance.sort_values(ascending=False, inplace=True, by=0)\n",
        "\n",
        "    feature_importance['pareto'] = 100 * feature_importance[0].cumsum() / feature_importance[0].sum()\n",
        "    feature_importance.rename(columns={0: 'importance'}, inplace=True)\n",
        "\n",
        "    fig, axes = plt.subplots(figsize=(16, 9))\n",
        "    ax1 = feature_importance.plot(use_index=True, y='importance', kind='bar', ax=axes, color=cmap(150))\n",
        "    ax2 = feature_importance.plot(use_index=True, y='pareto', marker='D', color=cmap(7), kind='line', ax=axes,\n",
        "                                  secondary_y=True)\n",
        "    ax2.set_ylim([0, 110])\n",
        "    ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title(f\"feature importances given by '.feature_importances_' for {grid_dt_optimized.__class__.__name__}\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        " \n",
        "importance = grid_dt_optimized.feature_importances_\n",
        "feature_importance = pd.DataFrame(importance, X_train.columns)\n",
        "\n",
        "print_feature_importance(feature_importance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Wnnf2ofhHn"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d94dU-w8s7Z"
      },
      "source": [
        "# [2, 6, 10, 14...]\n",
        "max_depth = np.arange(2, 22, 4)\n",
        "# [5, 10, 25, 50, 100, 150]\n",
        "n_estimators = [5, 10, 25, 50, 100, 150]\n",
        "\n",
        "# perform grid search\n",
        "param_grid = {'criterion': ['gini', 'entropy'], 'max_depth': max_depth, 'n_estimators': n_estimators,\n",
        "              'max_features': ['auto', 'sqrt', 'log2']}\n",
        "grid_rf = GridSearchCV(RandomForestClassifier(), param_grid, refit=True, verbose=0)\n",
        "grid_rf.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# choose best model\n",
        "grid_rf_optimized = grid_rf.best_estimator_\n",
        "\n",
        "# print confusion \n",
        "performance = print_results(grid_rf_optimized, performance)\n",
        "\n",
        "print_performance_measures(grid_rf_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5YqLiJVC_Bs"
      },
      "source": [
        "performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_14aX_YQS2RE"
      },
      "source": [
        "### Bagging"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VB0JjmOS0CE"
      },
      "source": [
        "# TODO: Validate results with larger dataset\n",
        "\n",
        "# perform grid search\n",
        "param_grid = {'n_estimators': [5, 10, 25, 50, 100, 150], 'max_samples': [1, 2, 3, 4, 5], 'max_features': [1, 2, 3]}\n",
        "#'base_estimator': ['SVC()', 'DecisionTreeClassifier()', 'RandomForestClassifier()'], \n",
        "grid_bag = GridSearchCV(BaggingClassifier(), param_grid, refit=True, verbose=0)\n",
        "grid_bag.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# choose best model\n",
        "grid_bag_optimized = grid_bag.best_estimator_\n",
        "\n",
        "# print confusion \n",
        "performance = print_results(grid_bag_optimized, performance)\n",
        "print_performance_measures(grid_bag_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A06jX15vyauv"
      },
      "source": [
        "param_grid = {\n",
        "    'base_estimator__max_depth' : [1, 2, 3, 4, 5],\n",
        "    'max_samples' : [0.05, 0.1, 0.2, 0.5]\n",
        "}\n",
        "\n",
        "grid_bag = GridSearchCV(BaggingClassifier(DecisionTreeClassifier(),\n",
        "                                     n_estimators = 100, max_features = 0.5),\n",
        "                   param_grid)\n",
        "grid_bag.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "\n",
        "# choose best model\n",
        "grid_bag_optimized = grid_bag.best_estimator_\n",
        "\n",
        "# print confusion \n",
        "performance = print_results(grid_bag_optimized, performance)\n",
        "print_performance_measures(grid_bag_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMNnyXf5Os1n"
      },
      "source": [
        "min_depth = 2\n",
        "step_size = 4\n",
        "step_count = 2 ** 4\n",
        "max_depth = min_depth + np.arange(step_count) * step_size\n",
        "\n",
        "param_grid = {\n",
        "    'base_estimator__max_depth' : max_depth,\n",
        "    'base_estimator__criterion': ['gini', 'entropy'],\n",
        "    'max_samples' : [0.05, 0.1, 0.2, 0.5]\n",
        "}\n",
        "\n",
        "grid_bag = GridSearchCV(BaggingClassifier(DecisionTreeClassifier(),\n",
        "                                     n_estimators = 100, max_features = 0.5),\n",
        "                   param_grid)\n",
        "grid_bag.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "\n",
        "# choose best model\n",
        "grid_bag_optimized = grid_bag.best_estimator_\n",
        "\n",
        "# print confusion \n",
        "performance = print_results(grid_bag_optimized, performance)\n",
        "print_performance_measures(grid_bag_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLlMfSklDDNV"
      },
      "source": [
        "performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhqpa3yWGUFm"
      },
      "source": [
        "### Support Vector Machine\n",
        "\n",
        "Next, we look at SVM with two different kernels. Namely, a rfb kernel and linear kernel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1326iBdkGTk2"
      },
      "source": [
        "min_c = 0.1\n",
        "step_size = 0.1\n",
        "step_count = 15\n",
        "\n",
        "C = min_c + np.arange(step_count) * step_size\n",
        "\n",
        "param_grid = {'C': [0.1, 1], 'gamma': [1, 0.1], 'kernel': ['rbf', 'linear']}\n",
        "grid_svm = GridSearchCV(SVC(), param_grid, refit=True, verbose=0, n_jobs=-1)\n",
        "grid_svm.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# choose best model\n",
        "grid_svm_optimized = grid_svm.best_estimator_\n",
        "\n",
        "# print confusion \n",
        "performance = print_results(grid_svm_optimized, performance)\n",
        "\n",
        "print_performance_measures(grid_svm_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njalvJAGDFdO"
      },
      "source": [
        "performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJzOuADbM6HR"
      },
      "source": [
        "### Neural Network "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ra4pmhqP139"
      },
      "source": [
        "param_grid = {'activation': ['logistic', 'relu'], 'learning_rate': ['constant', 'invscaling'],\n",
        "              'hidden_layer_sizes': [(100, 1), (100, 2)], 'early_stopping': True}\n",
        "grid_nn = GridSearchCV(MLPClassifier(), param_grid, refit=True, verbose=0)\n",
        "grid_nn.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# choose best model\n",
        "grid_nn_optimized = grid_nn.best_estimator_\n",
        "\n",
        "# print confusion \n",
        "performance = print_results(grid_nn_optimized, performance)\n",
        "\n",
        "print_performance_measures(grid_nn_optimized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htS7cXulDG8u"
      },
      "source": [
        "performance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99abplKtSu6V"
      },
      "source": [
        "## Voting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBxY_wPKTFGk"
      },
      "source": [
        "# TODO: Optional. Combine the best Classifiers e. g. SVM and RF\n",
        "model_voting = VotingClassifier(estimators=[('SVM', grid_svm_optimized), ('Random Forest', model_rf_optimized)],\n",
        "                                   voting='hard')\n",
        "model_voting.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "# print confusion matrix\n",
        "performance = print_result(model_voting, performance)\n",
        "\n",
        "print_performance_measures(model_voting)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O3ubD82C6YH"
      },
      "source": [
        "## Stacking Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwtvXsUJC5-R"
      },
      "source": [
        "# TODO: insert Code\n",
        "estimators = [('Neural Net', grid_nn_optimized), ('Random Forest', grid_rf_optimized)]\n",
        "model_stacked = StackingClassifier(estimators=estimators,\n",
        "                                   final_estimator=LogisticRegression(max_iter=200, penalty='l1', solver='liblinear'))\n",
        "\n",
        "model_stacked.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "performance = print_results(model_stacked, performance)\n",
        "\n",
        "print_performance_measures(model_stacked)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oBUFLWDU118"
      },
      "source": [
        "Bringing it all together...."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyyaBF8ecxxQ"
      },
      "source": [
        "##Task 5: Use LASSO for variable selection and explain results. (15 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxXdGBWyc6eM"
      },
      "source": [
        "In Task 5 we use a LASSO model for variable selection. First we run a grid search to find a suitable value for the penalty weight $\\alpha$. We use the metric Area under the curve (AUC) is the criteria for model selection."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "033BppfMdCyL"
      },
      "source": [
        "# TODO: LASSO for classification -> < 0.5 / > 0.5?\n",
        "# TODO: Discussion suitable for classifcation / automatic feature selection (pros and cons) \n",
        "# TODO: Move to end\n",
        "\n",
        "# use LassoCV to find the optimal alpha\n",
        "lasso = LassoCV(cv=5, random_state=0, max_iter=5000).fit(X, y)\n",
        "model = SelectFromModel(lasso, prefit=True)\n",
        "X_new = model.transform(X)\n",
        "print('X shape: ', X_new.shape)\n",
        "print('lasso_coef: ', lasso.coef_)\n",
        "print('lasso_intercept: ', lasso.intercept_)\n",
        "print('lasso_alpha: ', lasso.alpha_)\n",
        "lasso_alpha = lasso.alpha_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDGBMp0wd6ih"
      },
      "source": [
        "Next we look at coefficient of the optimized alpha...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ6xfsd0eG5j"
      },
      "source": [
        "coef_importance = pd.DataFrame(lasso.coef_, index=X.columns)\n",
        "coef_importance.rename(columns={0: 'importance'}, inplace=True)\n",
        "coef_importance = coef_importance.iloc[(-np.abs(coef_importance['importance'].values)).argsort()]\n",
        "\n",
        "fig, axes = plt.subplots(figsize=(16, 9))\n",
        "ax1 = coef_importance.plot(use_index=True, y='importance', kind='bar', ax=axes, color=cmap(150), legend=False)\n",
        "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45, ha='right')\n",
        "plt.xticks(rotation=45)\n",
        "plt.title(f\"abs. feature importances given by '.coef' for {model.__class__.__name__}\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUITxIqaeLm5"
      },
      "source": [
        "And more general for varying alpha...."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnvkPVOzeSws"
      },
      "source": [
        "alphas_lasso, coefs_lasso, _ = lasso_path(X, y, n_alphas=20, fit_intercept=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ChUTLOyeZn6"
      },
      "source": [
        "neg_log_alphas_lasso = -np.log10(alphas_lasso)\n",
        "\n",
        "# create df with coefs and their importance\n",
        "df_test = pd.DataFrame(coefs_lasso[0], index=X.columns)\n",
        "df_test.columns = neg_log_alphas_lasso\n",
        "\n",
        "# TODO: logscale y axis\n",
        "\n",
        "# plot\n",
        "plt.figure(figsize=(20, 20))\n",
        "g = sns.lineplot(data=df_test.T)\n",
        "plt.xlabel('-log(alpha)')\n",
        "plt.ylabel('coefficients')\n",
        "plt.title('Lasso paths')\n",
        "plt.legend(bbox_to_anchor=(1.1, 1))\n",
        "plt.show(g);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1S83UB1Lpop"
      },
      "source": [
        "performance"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}